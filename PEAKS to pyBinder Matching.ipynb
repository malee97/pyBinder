{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c31e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a09457",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.join('E:/','Lumos_Data','20220531 - 256-092 12ca5 vs ACE2')\n",
    "prots = ['12ca5','ACE2']\n",
    "rt_lim = 300\n",
    "\n",
    "files_peaks = ['ModelSelection_All_MS2s_12ca5.csv','ModelSelection_All_MS2s_ACE2.csv']\n",
    "files_pyb = ['12ca5 Full Output.csv', 'ACE2 Full Output.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2154d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mzs_peaks = []\n",
    "rts_peaks = []\n",
    "ALCs_peaks = []\n",
    "\n",
    "mzs_pyb = []\n",
    "rts_pyb = []\n",
    "es_pyb = []\n",
    "ps_pyb = []\n",
    "areas_pyb = []\n",
    "\n",
    "all_found_mzs = []\n",
    "all_found_rts = []\n",
    "all_found_es = []\n",
    "all_found_ps = []\n",
    "all_found_ALCs = []\n",
    "all_found_areas = []\n",
    "\n",
    "all_notfound_mzs = []\n",
    "all_notfound_rts = []\n",
    "all_notfound_es = []\n",
    "all_notfound_ps = []\n",
    "all_notfound_areas = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ab7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files_pyb:\n",
    "    mzs_prot = []\n",
    "    rts_prot = []\n",
    "    es_prot = []\n",
    "    ps_prot = []\n",
    "    areas_prot = []\n",
    "    with open(os.path.join(working_dir,file),mode='r',encoding='utf-8-sig') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file,delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            mzs_prot.append(float(row['mz']))\n",
    "            rts_prot.append(float(row['RT']))\n",
    "            es_prot.append(float(row['Escore']))\n",
    "            ps_prot.append(float(row['p value']))\n",
    "            areas_prot.append(row['areas'])\n",
    "    mzs_pyb.append(mzs_prot)\n",
    "    rts_pyb.append(rts_prot)\n",
    "    es_pyb.append(es_prot)\n",
    "    ps_pyb.append(ps_prot)\n",
    "    areas_pyb.append(areas_prot)\n",
    "\n",
    "for file in files_peaks:\n",
    "    mzs_prot = []\n",
    "    rts_prot = []\n",
    "    ALCs_prot = []\n",
    "    with open(os.path.join(working_dir,file),mode='r',encoding='utf-8-sig') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file,delimiter=',')\n",
    "        for row in csv_reader:\n",
    "            mzs_prot.append(float(row['mz']))\n",
    "            rts_prot.append(float(row['RT'])*60)\n",
    "            ALCs_prot.append(float(row['ALC']))\n",
    "    mzs_peaks.append(mzs_prot)\n",
    "    rts_peaks.append(rts_prot)\n",
    "    ALCs_peaks.append(ALCs_prot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d986a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,mz_peaks in enumerate(mzs_peaks):\n",
    "    rt_peaks = rts_peaks[i]\n",
    "    mz_pyb = mzs_pyb[i]\n",
    "    rt_pyb = rts_pyb[i]\n",
    "    e_pyb = es_pyb[i]\n",
    "    p_pyb = ps_pyb[i]\n",
    "    area_pyb = areas_pyb[i]\n",
    "    ALCs = ALCs_peaks[i]\n",
    "\n",
    "    mzs_found = []\n",
    "    rts_found = []\n",
    "    es_found = []\n",
    "    ps_found = []\n",
    "    areas_found = []\n",
    "    ALCs_found = []\n",
    "\n",
    "    mzs_notfound = []\n",
    "    rts_notfound = []\n",
    "    es_notfound = []\n",
    "    ps_notfound = []\n",
    "    areas_notfound = []\n",
    "    is_feature_in = 0\n",
    "    for j,mz in enumerate(mz_pyb):\n",
    "        if np.round(mz,2) in np.round(mz_peaks,2):\n",
    "            idx = np.where(np.round(mz_peaks,2) == np.round(mz,2))[0][0]\n",
    "            rt_id_peaks = rt_peaks[idx]\n",
    "            if (rt_pyb[j] - rt_lim < rt_id_peaks) and (rt_pyb[j] + rt_lim > rt_id_peaks):\n",
    "                mzs_found.append(mz)\n",
    "                rts_found.append(rt_pyb[j])\n",
    "                es_found.append(e_pyb[j])\n",
    "                ps_found.append(p_pyb[j])\n",
    "                areas_found.append(area_pyb[j])\n",
    "                ALCs_found.append(ALCs[idx])\n",
    "                is_feature_in -= -1\n",
    "            else:\n",
    "                mzs_notfound.append(mz)\n",
    "                rts_notfound.append(rt_pyb[j])\n",
    "                es_notfound.append(e_pyb[j])\n",
    "                ps_notfound.append(p_pyb[j])\n",
    "                areas_notfound.append(area_pyb[j])\n",
    "        else:\n",
    "            mzs_notfound.append(mz)\n",
    "            rts_notfound.append(rt_pyb[j])\n",
    "            es_notfound.append(e_pyb[j])\n",
    "            ps_notfound.append(p_pyb[j])\n",
    "            areas_notfound.append(area_pyb[j])\n",
    "    all_found_mzs.append(mzs_found)\n",
    "    all_found_rts.append(rts_found)\n",
    "    all_found_es.append(es_found)\n",
    "    all_found_ps.append(ps_found)\n",
    "    all_found_ALCs.append(ALCs_found)\n",
    "    all_found_areas.append(areas_found)\n",
    "\n",
    "    all_notfound_mzs.append(mzs_notfound)\n",
    "    all_notfound_rts.append(rts_notfound)\n",
    "    all_notfound_es.append(es_notfound)\n",
    "    all_notfound_ps.append(ps_notfound)\n",
    "    all_notfound_areas.append(areas_notfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492c204b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(14, 10))\n",
    "# fig = plt.figure()  # for 3D plots\n",
    "for i in range(len(prots)):\n",
    "    e_f = all_found_es[i]\n",
    "    p_f = [-np.log10(p) for p in all_found_ps[i]]\n",
    "    e_nf = all_notfound_es[i]\n",
    "    p_nf = [-np.log10(p) for p in all_notfound_ps[i]]\n",
    "    ALCs_f = all_found_ALCs[i]\n",
    "\n",
    "    ALCs_sorted = np.sort(ALCs_f)[::-1]\n",
    "    idxs_sorted = np.argsort(ALCs_f)[::-1]\n",
    "    e_f_sorted = [e_f[j] for j in idxs_sorted]\n",
    "    p_f_sorted = [p_f[j] for j in idxs_sorted]\n",
    "\n",
    "    #### 3D plotting stuff\n",
    "    # ax = fig.add_subplot(1,2,i+1,projection='3d')\n",
    "    # ax.scatter(e_f_sorted,p_f_sorted,ALCs_sorted,c=ALCs_sorted,cmap='gnuplot',linewidth=0.5)\n",
    "    # ax.plot_trisurf(e_f_sorted,p_f_sorted,ALCs_sorted,cmap='gnuplot',edgecolor='none')\n",
    "    #### end 3D plotting stuff\n",
    "\n",
    "    axs[i].scatter(e_nf, p_nf, c='gray', label='Found in pyBinder')\n",
    "    cb = axs[i].scatter(e_f_sorted, p_f_sorted, c=ALCs_f,alpha=1,cmap='gnuplot',label='Found in PEAKS and pyBinder',vmin=70)\n",
    "    axs[i].set_xscale('linear')\n",
    "    axs[i].set_xlim([0, 1])\n",
    "    axs[i].set_yscale('linear')\n",
    "    axs[i].set_title(f'Volcano plot for {prots[i]}', fontsize=24)\n",
    "    axs[i].set_xlabel('Enrichment Score', fontsize=20)\n",
    "    axs[i].set_ylabel('-Log10(P value)', fontsize=20)\n",
    "    axs[i].legend(loc='best', fontsize=14)\n",
    "    axs[i].tick_params(axis='both', which='major', labelsize=16)\n",
    "fig.colorbar(cb,ax=axs.ravel().tolist(),label='ALC Score (%)',orientation='vertical')\n",
    "figname = 'PEAKS sequences mapped to volcano all MS2.png'\n",
    "plt.savefig(os.path.join(working_dir,figname))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,scores in enumerate(all_found_es):\n",
    "    df = pd.DataFrame(columns=('Compound', 'm/z','p value','specificity'))\n",
    "    RT = all_found_rts[i]\n",
    "    mz = all_found_mzs[i]\n",
    "    ps = all_found_ps[i]\n",
    "    areas = all_found_areas[i]\n",
    "    for j,score in enumerate(scores):\n",
    "        A = 'EScore: ' + str(np.round(score,2)) + ' RTime: ' + str(np.round(RT[j],3))\n",
    "        B = np.round(mz[j],4)\n",
    "        C = float(ps[j])\n",
    "        D = prots[i]\n",
    "        df.loc[j] = [A,B,C,D]\n",
    "    df.to_csv(os.path.join(working_dir,prots[i] + ' Found pyB.csv'),index=False)\n",
    "\n",
    "for i,scores in enumerate(all_notfound_es):\n",
    "    df = pd.DataFrame(columns=('Compound', 'm/z','p value','specificity'))\n",
    "    RT = all_notfound_rts[i]\n",
    "    mz = all_notfound_mzs[i]\n",
    "    ps = all_notfound_ps[i]\n",
    "    for j,score in enumerate(scores):\n",
    "        A = 'EScore: ' + str(np.round(score,2)) + ' RTime: ' + str(np.round(RT[j],3))\n",
    "        B = np.round(mz[j],4)\n",
    "        C = float(ps[j])\n",
    "        D = prots[i]\n",
    "        df.loc[j] = [A,B,C,D]\n",
    "    df.to_csv(os.path.join(working_dir,prots[i] + ' Not Found pyB.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ce073",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get stuff not found in PEAKS\n",
    "\n",
    "all_found_mzs_peaks = []\n",
    "all_found_rts_peaks = []\n",
    "all_found_es_peaks = []\n",
    "all_found_ps_peaks = []\n",
    "\n",
    "all_notfound_mzs_peaks = []\n",
    "all_notfound_rts_peaks = []\n",
    "all_notfound_es_peaks = []\n",
    "all_notfound_ps_peaks = []\n",
    "\n",
    "for i,mz_peaks in enumerate(mzs_peaks):\n",
    "    rt_peaks = rts_peaks[i]\n",
    "    mz_pyb = mzs_pyb[i]\n",
    "    rt_pyb = rts_pyb[i]\n",
    "    e_pyb = es_pyb[i]\n",
    "    p_pyb = ps_pyb[i]\n",
    "\n",
    "    mzs_found_peaks = []\n",
    "    rts_found_peaks = []\n",
    "\n",
    "    mzs_notfound_peaks = []\n",
    "    rts_notfound_peaks = []\n",
    "    is_feature_in = 0\n",
    "    for j,mz in enumerate(mz_peaks):\n",
    "        if np.round(mz,2) in np.round(mz_pyb,2):\n",
    "            idx = np.where(np.round(mz_pyb,2) == np.round(mz,2))[0][0]\n",
    "            rt_id_pyb = rt_pyb[idx]\n",
    "            if (rt_peaks[j] - rt_lim < rt_id_pyb) and (rt_peaks[j] + rt_lim > rt_id_pyb):\n",
    "                mzs_found_peaks.append(mz)\n",
    "                rts_found_peaks.append(rt_peaks[j])\n",
    "                is_feature_in -= -1\n",
    "            else:\n",
    "                mzs_notfound_peaks.append(mz)\n",
    "                rts_notfound_peaks.append(rt_peaks[j])\n",
    "        else:\n",
    "            mzs_notfound_peaks.append(mz)\n",
    "            rts_notfound_peaks.append(rt_peaks[j])\n",
    "    all_found_mzs_peaks.append(mzs_found_peaks)\n",
    "    all_found_rts_peaks.append(rts_found_peaks)\n",
    "\n",
    "    all_notfound_mzs_peaks.append(mzs_notfound_peaks)\n",
    "    all_notfound_rts_peaks.append(rts_notfound_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,mzs in enumerate(all_found_mzs_peaks):\n",
    "    df = pd.DataFrame(columns=('RT', 'm/z','specificity'))\n",
    "    RT = all_found_rts_peaks[i]\n",
    "    for j,mz in enumerate(mzs):\n",
    "        A = 'RTime: ' + str(np.round(RT[j],3))\n",
    "        B = np.round(mz,4)\n",
    "        C = prots[i]\n",
    "        df.loc[j] = [A,B,C]\n",
    "    df.to_csv(os.path.join(working_dir,prots[i] + ' Found PEAKS All ms2.csv'),index=False)\n",
    "\n",
    "for i,mzs in enumerate(all_notfound_mzs_peaks):\n",
    "    df = pd.DataFrame(columns=('RT', 'm/z','specificity'))\n",
    "    RT = all_notfound_rts_peaks[i]\n",
    "    for j,mz in enumerate(mzs):\n",
    "        A = 'RTime: ' + str(np.round(RT[j],3))\n",
    "        B = np.round(mz,4)\n",
    "        C = prots[i]\n",
    "        df.loc[j] = [A,B,C]\n",
    "    df.to_csv(os.path.join(working_dir,prots[i] + ' Not Found PEAKS All ms2.csv'),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
